library(readr)
spiritwt_data <- read_csv("C:/knot4u/UTD/6301/Lecture Material/Datasets/Lecture-13-Data/spiritwt_data.csv",
col_names = FALSE)
View(spiritwt_data)
colnames(spiritwt_data)=c("Temp","Dilution","Wght")
lr.model = lm(Wght~Temp+Dilution, data=spiritwt_data)
summary(lr.model)
dim(spiritwt_data)
# Here we select the rows that we will use to train the model
train = sample(315,215)
lr.model.1 = lm(Wght~Temp+Dilution, data=spiritwt_data, subset=train)
# R automatically uses only the rows in the train subset to
# create the model
summary(lr.model.1)
# Still looks pretty good ...
# Here is how we can calculate the training MSE
mean(lr.model.1$residuals^2)
# Is this good?
summary(spiritwt_data$Wght)
# The SQRT(MSE) is about 0.7% of the average WGHT, so
# probably a good result. But what about the Test MSE?
attach((spiritwt_data))
mean((Wght - predict(lr.model.1,spiritwt_data))[-train]^2)
# Pretty good so far - but this is just one Test set.
# To do LOOCV, we need to attach 'boot'
library("boot", lib.loc="C:/Program Files/R/R-3.3.2/library")
lr.model.2 = glm(Wght~Dilution+Temp, data=spiritwt_data)
summary(lr.model.2)
# Note this gives the same model (coefficients are the same)
# But the summary provides different information
# This does LOOCV ...
cv.error.2 = cv.glm(spiritwt_data,lr.model.2)
cv.error.2$delta
# In line with the Test MSE we saw earlier ...
?cv.glm
plot(lr.model.2$residuals~ Dilution)
# Definitely looks like a nonlinear effect - what order
# poly to use? Let's test several ...
cv.error = rep(0,8)
for(i in 1:8){
glm.fit=glm(Wght~Temp+poly(Dilution,i), data=spiritwt_data)
cv.error[i]=cv.glm(spiritwt_data,glm.fit)$delta[1]
}
plot(cv.error)
# Looks like a quadratic gives the best result
cv.error
# The plot is deceptive - the best ploynomial is actually
# 4th order.
library(readr)
airfoil_self_noise <- read_delim("C:/knot4u/UTD/6301/Lecture Material/Datasets/Lecture-13-Data/airfoil_self_noise.dat",
"\t", escape_double = FALSE, trim_ws = TRUE)
View(airfoil_self_noise)
summary(airfoil_self_noise)
plot(airfoil_self_noise)
# Let's try the above method to see what level of polynomial
# works ...
cv.error.airfoil = rep(0,5)
attach(airfoil_self_noise)
for(i in 1:5){
glm.fit = glm(SoundLev~poly(Freq,i)+poly(Angle,i)+ChordLen + Velocity+poly(Displace,i),data=airfoil_self_noise)
cv.error.airfoil[i] = cv.glm(airfoil_self_noise,glm.fit,K=10)$delta[1]
}
cv.error.airfoil
# We applied 10-fold CV on each model to compare the MSEs ...
# There does not seem to be  big difference
# Let's look at the linear model
glm.fit = glm(SoundLev~Freq+Angle+ChordLen+Velocity+Displace, data=airfoil_self_noise)
summary(glm.fit)
plot(glm.fit$residuals~glm.fit$fitted.values)
cv.out=cv.glm(airfoil_self_noise,glm.fit,K=10)
cv.out$delta[1]
summary(airfoil_self_noise$SoundLev)
# Our SQRT(MSE) is about 3.8% of the mean value
# Let's try adding some cross terms
glm.fit = glm(SoundLev~Freq+Angle+ChordLen+Velocity+Displace+Freq*Angle+Angle*Displace+Freq*Displace, data=airfoil_self_noise)
summary(glm.fit)
glm.fit = glm(SoundLev~Freq+Angle+ChordLen+Velocity+Displace+Freq*Angle, data=airfoil_self_noise)
cv.out = cv.glm(airfoil_self_noise,glm.fit,K=10)
cv.out$delta[1]
# Slightly better ...
library(readr)
ENB2012_data <- read_delim("C:/knot4u/UTD/6301/Lecture Material/Datasets/Lecture-13-Data/ENB2012_data.txt",
"\t", escape_double = FALSE, trim_ws = TRUE)
View(ENB2012_data)
summary(ENB2012_data)
# We need to remove the last two columns and clean up
myData = ENB2012_data[,-11]
myData = myData[,-11]
myData = na.omit(myData)
summary(myData)
dim(myData)
myData$X8 = as.factor(myData$X8)
myData$X6 = as.factor(myData$X6)
summary(myData)
glm.fit = glm(Y1~.-Y2, data=myData)
summary(glm.fit)
# We see X6 is not significant, and X4 is collinear
glm.fit = glm(Y1~.-Y2 -X6 -X4, data=myData)
summary(glm.fit)
cv.out=cv.glm(myData,glm.fit, K=10)
cv.out$delta[1]
summary(myData$Y1)
# SQRT(MSE) is about 12.6% of the average value of Y1
plot(glm.fit$residuals~glm.fit$fitted.values)
savehistory("C:/knot4u/UTD/6301/Lecture Material/R Scripts/Lecture-13.Rhistory")
